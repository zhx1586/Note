# Faster R-CNN：通过区域推荐算法来实现实时目标检测

## 摘要

目前最先进的区域检测算法依靠区域推荐算法来预测物体的位置。
像SPPnet和Fast R-CNN这样的进步减少了这些检测网络的运行时间，使得区域推荐的计算成为了瓶颈。
在本文的工作中，我们引入了区域推荐网络（RPN），它使用了与检测网络相同的全图像卷积特征，因此能够实现几乎无成本的区域推荐。
区域推荐网络（RPN）是一个完全的卷积网络，它同时预测了目标边界和每个位置的客观得分。
该区域推荐网络（RPN）通过端对端（端对端：输入原始数据，输出最终结果，没有人工预处理）训练来产生高质量的区域推荐，这些区域推荐被Fast R-CNN用来进行检测。
我们通过统一PRN和Fast R-CNN的卷积特征来进一步将它们合并成一个网络，其中的RPN部分告诉整个网络去哪里寻找目标，这种方法用最近流行的神经网络术语来说就是“注意机制（attention mechanisms）”。
对于层数较多的VGG-16模型，我们的检测系统在GPU上达到了5帧/秒的处理速度，在PASCAL VOC 2007,2012 和 MS COCO 数据集上仅需每张图片300个推荐就达到了最先进的目标检测精度。
在ILSVRC 和 COCO 2015 比赛中，Faster R-CNN 和 PRN 是许多项目冠军的设计基础。
代码实现了开源。

关键词：目标检测、区域推荐、卷积神经网络

## 1 绪论

近期目标检测领域的进步是由区域推荐算法和基于区域的卷积神经网络（R-CNN）的成功所驱动的。
尽管R-CNN 算法在最初开发时是计算昂贵，跨特征分享卷积使得该算法的计算开销大大降低了。
最新的成果 Fast R-CNN 在层数较多的神经网络上实现了接近实时处理的速率，在忽略区域推荐部分的时间开销的情况下。
目前，区域推荐部分是整个算法的计算瓶颈。

区域推荐算法倾向于使用廉价的特征和经济的推理方法。
选择搜索（Selective Search）算法，最流行的方法之一，基于工程低级特征对超像素进行了贪婪地合并。
然而，与高效的检测网络相比，选择搜索慢了一个数量级，在CPU上是实现时达到了2帧/秒的速度。
EdgeBoxes 目前提供了在推荐质量和速度上的最佳折中，达到了5帧/秒的速度。
但是，EdgeBoxes算法的区域推荐步骤也消耗了与检测网络相同的运行时间。

可能有人会指出，R-CNN 算法借助了GPU的计算优势，然而区域推荐部分的算法是实现在CPU上的，进行这种运行时间的比较是不公平的。
一个明显的加速推荐计算的方法是在GPU上重新实现。
这可能是一个有效的工程上的解决方法，但是重新实现的过程中忽视了下游的检测网络，因此错过了共享计算的重要机会。

在这篇文章中，我们证明了算法上的改进--通过一个深度卷积网络来计算区域推荐--能够得到一个更加优雅和高效的解决方法，使得在已知检测网络的计算的前提下，区域推荐计算能够几乎无成本地实现。
为此，我们引入了新兴的区域推荐网络（RPNs），它与目标检测网络使用相同的卷积层。
通过在检测时共享卷积层，计算推荐的时间开销会非常小（10ms/frame）。

我们注意到 Fast R-CNN 等基于区域的检测算法使用的卷积特征映射也能用在生成区域推荐上。
在这些卷积特征的顶部，我们通过增加一些额外的卷积层来构建一个区域推荐网络（RPN），这些额外的卷积层能够同时对区域边界和规则网络中每个位置的客观评价进行回归计算。
因此这些区域推荐网络（RPN）实际上是一种完全卷积网络（FCN），并且可以为产生检测推荐这一特定任务进行端对端训练。

区域推荐网络（RPN）被设计为可以高效地预测具有大范围尺寸和长宽比的区域推荐。
与流行的方法相反，区域推荐网络使用图像金字塔或者滤波器金字塔，我们引入新兴的“archor”框，这种框用于多尺度和长宽比的参考。
我们的方案可以被认为是回归参考的金字塔，这样做可以避免列举多种尺寸的图像或滤波器。
这种模型在训练和测试单一尺寸的图像时表现得很好，因此有利于提高运行速度。

为了将区域推荐网络（RPN）统一到 Fast R-CNN 目标检测网络中，我们提出了一种训练方法，即在保持推荐固定的前提下交替进行区域推荐任务和目标检测任务的微调。
这种方法收敛很快，并且能够产生一个含有两种任务共享的卷积特征的统一网络。

我们在PASCAL VOC检测基准上对这个算法进行了综合评测，在这个检测基准上 RPN 加 Fast R-CNN 的精度比 Selective Search 加 Fast R-CNN 更高。

这份手稿的一个初步版本之前已经发布过了。从那时候起，RPN+Fast R-CNN框架已经被应用和推广到了其他方法中，例如三维目标检测、基于部分的检测、实例分割以及图像字幕等领域。
我们速度快而且高效的目标检测系统也已经被应用到了商业系统中。

在ILSVRC 和 COCO 2015 比赛中，Faster R-CNN 和 PRN 是许多项目冠军的设计基础，例如ImageNet detection, ImageNet localization, COCO detection 和 COCO segmentation。
区域推荐网络（RPN）完全从数据中学习去推荐区域，因此能够轻易获得更深更有价值的特征所带来的好处。
Faster R-CNN 和 PRN也可以用在这些比赛的许多其他项目上。
这些结果表明我们的方法不仅是工程实践中减少时间开销的一个方法，更是一个有效提高目标检测精度的方法。

## 2 相关工作

- 目标推荐。广泛使用的目标推荐算法包括基于分组超像素的方法（例如 Selective Search）和基于滑动窗口的方法（例如EdgeBoxs）。目标推荐算法被视为独立于检测部分的扩展模块。

- 用于目标检测的深度神经网络。R-CNN方法使用端对端方法训练卷积神经网络，将推荐区域分类为对象类别或者背景。
R-CNN主要作为一个分类器，它并不预测物体的边界。它的精度主要取决于区域推荐模块的表现。
许多论文提出了使用深度网络预测物体边界框的方法。
在OverFeat方法中，为完成对单一物体的定位任务，训练了一个全连接层用于预测边界框的坐标。
这个全连接层之后被改为用于检测多个类特定对象的卷积层。
MultiBox方法从一个网络中产生区域推荐，网络中的最后一个全连接层同时预测多个类不可知的框，推广了OverFeat方法是“single-box”特性。
这些类不可知的框被用作对R-CNN的推荐。
MultiBox推荐网络可以应用在单一图像尺寸或者多种图像尺寸的情况下，与全卷积网络不同。
MultiBox并不在推荐和检测网络中共享特征。
与我们同时的还有DeepMask方法，这种方法是用来学习分割推荐的。

卷积的共享计算已经引起了越来越多的关注，用于高效准确的视觉识别。
OverFeat方法从一个图像金字塔中计算卷积特征，用于分类、定位和检测。
基于共享卷积特征映射的自适应尺寸池化（SPP）用于高效的基于区域的目标检测和语义分割。
Fast R-CNN 使得共享卷积特征上的端对端检测训练成为可能，并且展现出了引人注目的精确度和速度。

## 3 Faster R-CNN

Faster R-CNN 目标检测系统由两个模块组成。第一个给模块是进行区域推荐的深度全卷积网络，第二个模块是使用区域推荐的检测子。
整个系统是一个用于目标检测的一个统一系统。
从“Attention mechanisms”角度来说，RPN模块告诉Fast R-CNN模块去图像的哪个位置寻找目标。
在3.1小节中，我们介绍了区域推荐网络的设计和特点。
在3.2小节中，我们开发了使用特征共享方法来训练两个模块的算法。

### 3.1 区域推荐网络（RPN）

RPN使用一个任意大小的图片作为输入，输出一个矩形目标推荐集合，每个推荐对应一个客观评分。
我们用一个全卷积网络来对这一过程进行建模，这将在本小节中讨论。
由于我们的最终目标是实现两个网络共享计算，我们假定两个网络具有一系列相同的卷积层。
在我们的实验中，我们研究了ZF模型（有5层共享卷积层）和VGG-16模型（有13层共享卷积层）。

为生成区域推荐，我们在最后一个共享卷积层的输出特征映射上滑动一个小的网络。
这个小网络把输入特征映射的一个 $n \times n$ 大小的框作为输入。
每个滑动窗口被映射为一个低维特征（ZF：256-d，VGG-16:512-d，之后是ReLU层）。
这些特征被输入到两个兄弟全连接层--一个框-回归层（reg）和一个框-分类层（cls）。
我们在这篇文章中使用 $n=3$ ，尽管输入图像上的有效接受区域（ZF：171 pixels，VGG：228
pixels）很大。
由于这个小网络是通过滑动窗口方式进行操作，其中的全连接层被整个空间区域共享。
这种架构可以通过一个 $n \times n$ 卷积层后面加两个 $1 \times 1$ 卷积层（如reg和cls）来实现。

#### 3.1.1 锚点（Anchors）

在每个滑动窗口的位置上，我们同时预测多种区域推荐，其中每个位置可能性最大的推荐标号记作 $k$。
因此reg层产生一个 $4k$ 大小的输出，用来编码 $k$ 个框的坐标，cls层产生一个 $2k$ 大小的输出，用来估计每个推荐是否是目标物体（假定cls层为两输出Softmax层）。
$k$ 个推荐相对于 $k$ 个框被参数化，我们将这称为锚点。
锚点在被研究的滑动窗口中心，并且与尺寸和长宽比相关联。
默认情况下，我们采用 $3$ 个尺寸和 $3$ 个长宽比，即在每个滑动位置产生 $9$ 个锚点。
对于一个大小为 $W \times H$（典型值为 $~2,400$ ）的卷积特征映射，总共有 $W \times H \times k$ 个锚点。

##### 翻译不变的锚点

我们采用方法的一个重要特性是它是翻译不变的，无论是在锚点还是相对于锚点计算推荐的函数。
如果翻译图像中的物体，那么推荐也应该翻译，并且相同的函数应该能够预测其他位置的推荐。
这种翻译不变特性是由采用的方法（FCN，Fully Convolutional Network）保证的。
作为比较，MultiBox方法采用 $k$-means 方法来产生 $800$ 个锚点，这种方法不是翻译不变的。
因此Multibox并不能保证在物体被翻译时相同的推荐也被翻译。

这种翻译不变特性也降低了模型的大小。
Multibox使用一个 $(4+1)\times 800$-维 的全连接输出层，而我们的方法使用一个 $(4+2)\times 9$-维 的卷积输出层，在 $k=9$ 的情况下。
结果是，我们的输出层具有 $2.8 \times 10^4$ 个参数（$512\times(4+2)\times9$ 对于VGG-16），比Multibox含有 $6.1\times10^6$ 个参数（$1536\times(4+1)\times800$ 对于GoogLeNet）的输出层少了两个数量级。
如果考虑特征投影层，我们的推荐层仍然比Multibox参数的数量级少。
我们期待我们的模型在小数据集上具有更少的过拟合风险，例如PASCAL VOC。

##### 多尺寸锚点作为回归参考

我们的锚点设计呈现出处理多尺寸多长宽比图像的新方法。
有两种对多尺寸图像进行预测的流行方法。
第一种方法是基于图像/特征金字塔的，例如在DPM和基于CNN的方法。
图像被调整为多种尺寸，特征映射被逐层计算。
这种方法很常用，但是很耗时。
第二种方法是在特征映射的多种尺寸（多种长宽比）上使用滑动窗口。
例如，在DPM中，不同长宽比的模型使用不同尺寸（例如 $5\times 7 和 7\times 5$）的滤波器分别训练。
如果这种方法用来处理多尺寸图像，它可以被认为是一种滤波器金字塔。
第二种方法通常与第一种方法共同使用。

作为比较，我们的基于锚点的方法使用锚点金字塔，这种方式更加合算。
我们的方法参考多尺寸多长宽比的锚点框来对边框进行分类和回归。
它仅仅依赖单一尺寸的图像和特征映射，使用单一尺寸的滤波器（特征映射上的滑动窗口）。
我们通过实验来展示这种方法寻址多尺寸图像的能力。

由于这种基于锚点的多尺寸设计，我们可以轻易使用单一尺寸图像计算得到的卷积特征，正如Fast R-CNN检测子所完成的。
这种多尺寸锚点的设计是几乎无代价分享特征的关键。

#### 3.1.2 代价函数

为训练RPN，我们为每个锚点分配一个二分类标签（是否是目标物体）。
我们为两种锚点分配正标签标签：（1）与真实目标框具有最大重合度的锚点（2）与真实目标框重合度大于 $0.7$ 的锚点。
注意单一真实目标框可能为多个锚点分配正标签。
通常第二种情况已经足够用来检测正样本，但是由于在很少的情况下第二种情况甚至无法检测出一个正样本，我们仍然采用第一种情况。
我们为非正的锚点分配一个负标签，如果它和所有真实目标框的重合度都小于 $0.3$。
既不是正标签也不是负标签的锚点对训练没有影响。

基于这些定义，我们按照Fast R-CNN 中多任务代价的方法来最小化目标函数。
对于一张图片的代价函数为：
\begin{align\*}
L\big(\\{p_i\\},\\{t_i\\}\big) &=  \frac{1}{N_{cls}}\sum_i L_{cls}\big(p_i,p_i^\*\big) +\lambda \frac{1}{N_{reg}} \sum_i p_i^{\*}L_{reg}\big(t_i,t_i^{\*}\big)
\end{align\*}
其中，$i$ 是一个小批次中锚点的索引，$p_i$ 是锚点 $i$ 是否是检测目标的预测概率。
真实目标框标签 $p_i^{*}$ 当锚点为正时值为 $1$，当锚点为负时值为 $0$。
$t_i$ 是代表预测框的 $4$ 个参数化坐标的向量，$t_i^{*}$ 则对应与正锚点关联的真实目标框。
分类损失$L_{cls}$是两个类（是目标和不是目标）的对数损失函数。
对于回归损失，我们使用 $L_{reg}\big(t_i,t_i^{*}\big)=R\big(t_i-t_i^{*}\big)$ 其中$R$是定义在Fast R-CNN 中的鲁棒损失函数。
项 $p_i^{*}L_{reg}$ 意味着回归损失仅被正锚点（$p_i^{*}=1$）激活，否则会被禁止（$p_i^{*}=0$）。
$cls$ 层和 $reg$ 层的输出分别由 $\{p_i\}$ 和 $\{t_i\}$ 组成。

这两项通过 $N_{cls}$ 和 $N_{reg}$ 来规范化，用一个平衡参数 $\lambda$ 来表示权重。
在我们目前的实现中，$cls$ 项使用一个小批次大小 （$i.e. N_{cls} = 256$）来实现规范化，$reg$ 项通过锚点位置（$i.e. N_{reg} = 2400$）来实现规范化。
默认情况下，我们设 $\lambda = 10$，因此这两项具有大致相等的权重。
我们通过实验展示了结果对 $\lambda$ 的变化并不敏感。
我们也注意到上述的规范化过程是不必要的，可以精简掉。

对于边界框回归，我们将四个坐标参数化为如下的形式：
\begin{align\*}
(t_x, t_y,t_w,t_h) &= \bigg(\frac{x-x_a}{w_a}, \frac{y-y_a}{h_a}, log \big(\frac{w}{w_a}\big),log \big(\frac{h}{h_a}\big)\bigg) \\\
(t_x^{\*}, t_y^{\*},t_w^{\*},t_h^{\*}) &= \bigg(\frac{x^{\*}-x_a}{w_a}, \frac{y^{\*}-y_a}{h_a}, log \big(\frac{w^{\*}}{w_a}\big),log \big(\frac{h^{\*}}{h_a}\big)\bigg)
\end{align\*}
其中$x$，$y$，$w$ 和 $h$表示框中心点坐标和框的宽度和高度。
变量$x$，$x_a$ 和 $x^*$ 分别表示预测框，锚点框和真实框（$y$，$w$，$h$类似）。
这可以被认为是从锚点框到附近真实狂的边界框回归过程。

但是，我们的方法在实现边界框回归时有别于基于RoI（Region of Interest）的方法。
在文献【1】中，边界框回归是在任意大小的RoI上池化得到的特征上进行的，回归权值被所有的区域尺寸共享。
在我们的方法中，用于回归的特征是特征映射上空间尺寸相同的部分（$3\times3$）。
为了说明不同的大小，需要学习 $k$ 个边界框回归子。
每个回归子对应一个尺寸和长宽比，$k$ 个回归子不共享权值。
因此，尽管特征是固定尺寸的，预测多种尺寸的边界框依旧是可能的，对亏了锚点设计。

#### 3.1.3 训练RPNs

RPN可以使用反向传播算法和随机梯度下降进行端对端训练。
我们按照文献【2】中的“image-centric”采样策略来训练这个网络。
每个mini-batch产生自一张含有多个正标签和负标签样本锚点的图片。
使用全部锚点来优化损失函数是可能的，但是这样会偏向负标签样本，因为它们是主导的。
作为代替，我们在一张图片上随机选取256个锚点来计算一个mini-batch的损失函数，其中正标签样本和负标签样本的锚点数比例为 $1:1$。
如果图像中的正标签样本数不足128个，我们使用负标签样本对mini-batch进行填充。

我们对所有新的层进行随机初始化，使用 $(\mu=0,\sigma=0.01)$ 的高斯分布。
所有的其他层（$i.e.$ 共享卷积层）使用ImageNet分类的预训练模型进行初始化，按照实践中的标准方法。
我们对ZF网络和conv3_1中的所有层进行微调，并更新到VGG网络中，来节省内存。
我们对 $60K$ 的mini-batch使用 $0.001$ 的学习速率，对接下来的 PASCAL VOC数据集上的 $20K$ mini-batch使用 $0.0001$ 的学习速率。
我们使用 $0.9$ 的冲量和 $0.0005$ 的权重衰减。
使用Caffe来实现。

### 3.2 为RPN和Fast R-CNN 共享卷积特征

到现在为止我们已经描述了如何训练一个用于生成区域推荐的网络，在不考虑应用这些推荐的R-CNN的情况下。
对于这个检测网络，我们采用Fast R-CNN。
接下来，我们会描述学习一个统一网络的算法，这个统一网络是由共享卷积层的 RPN 和 Fast R-CNN组成的。

单独训练的两个网络会按照不同的方式来修改它们自己的卷积层。
因此我们需要开发一种方法，这种方法允许在两个网络之间共享卷积层，而不是学习两个独立的网络。
我们讨论三种利用共享特征训练网络的方法：

- 1  交替训练（Alternating training）

在这种方法中，我们首先训练RPN，并且使用推荐来训练 Fast R-CNN。
被Fast R-CNN微调的网络接下来用于初始化RPN，之后这一过程被迭代执行。
这是这篇文章中的所有实验使用的方法。

- 2 近似联合训练（Approximate joint training）

RPN 和 Fast R-CNN 在训练时被合并成一个网络。
在每次随机梯度下降的迭代中，前向通路产生区域推荐，在训练Fast R-CNN检测子时，这些区域推荐被视为固定的、预先计算好的。
反向传播过程照常进行，对于共享层来说，来自两个网络的反向传播信号被结合起来了。
这种算法很容易实现。
但是这种方法忽略了对推荐框坐标的导数，这部分也是网络的响应，因此这种方法是近似的。
在我们的实验中，我们经验发现，这种优化算法产生相近的结果，但是与交替训练相比减少了 $25-50%$ 的训练时间。
这种优化算法包含在我们发布的Python代码中。

- 3 非近似联合训练（Non-approximate joint training）

如上文所述，RPN预测的边界框也是输入的函数。
Fast R-CNN 的RoI池化层既将卷积特征作为输入，又将预测的边界框作为输入，因此一个理论上正确的反向传播算子应该包含边界框坐标对应的梯度。
这些梯度在上面的近似联合训练中被忽略了。
在非近似联合训练方法中，我们需要一个对边界框坐标可微的RoI池化层。
这是非平凡的工作，解法由文献【15】中开发的RoI接口层给出，这已超出了这篇文章的范畴。

##### 四步交替训练（4-Step  alternating training）

在这篇文章中，我们采用了一个实用的四步训练法来通过交替优化算法学习共享特征。
在第一步中，我们按照3.1.3小结中介绍的方法训练RPN。
这个网络使用ImageNet预训练模型来初始化，为完成区域推荐任务进行端对端微调。
在第二步中，我们利用第一步中RPN产生的区域推荐单独训练出一个 Fast R-CNN检测网络。
检测网络依旧使用ImageNet预训练模型进行初始化。
此时，两个网络没有共享卷积层。
在第三步中，我们使用这个检测网络来初始化RPN训练，但是我们固定共享卷积层，仅仅对RPN中独有的层进行微调。
现在两个网络实现了卷积层的共享。
最后，保持共享的卷积层固定，对Fast R-CNN 中独有的层进行微调。
就这样，两个网络共享了相同的卷积层。
一个类似的交替训练可以进行多轮的迭代，但是我们仅仅观察到很小的进步。

#### 3.3 实现细节

### 4 实验结果

### 5 结论

我们已经提出了用于高效准确的区域推荐生成RPN。
通过与下游的检测网络共享卷积特征，区域推荐步骤几乎是无代价的完成的。
我们的方法使一个统一的、基于深度学习的物体检测系统能够运行在一个接近实时的帧率。
训练得到的RPN也提高了区域推荐质量，进而提高了整个物体检测系统的精确度。




