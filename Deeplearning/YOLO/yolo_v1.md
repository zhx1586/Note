# YOLO_V1

## 摘要

- 前人在目标检测领域的工作使用分类器来实现检测。相反，我们将目标检测视为对独立的空间边界框以及相关的类标签概率的回归问题。
- 使用一个神经网络来直接从一个样本的整张图片中预测边界框和类标签概率。由于整个检测步骤是一个网络，可以直接对检测能力进行端到端的优化。

##  1 引言

- 目前的目标检测系统使用分类器来实现检测。为了检测一个目标，这些系统为该物体建立一个分类器，并且在待测图片的多个位置和尺度上进行评估。Deformable Parts Models（DPM）等系统使用一种滑动窗口方法，在整张图片上均匀分布的位置上运行分类器。
- 更新的方法，例如R-CNN， 使用区域推荐方法首先生成一个图片中潜在的边界框，之后在这些推荐的边界框上运行分类器。之后，使用后处理步骤来优化边界框，消除重复检测，基于场景中的其他目标对边界框再次评估。这些复杂的步骤在运行时很耗时，而且由于每个组件必须被分别训练，很难对整个步骤进行优化。
- 我们将目标检测视为一个独立的回归问题，直接从图片像素到边界框顶点坐标和类标签概率。
- YOLO 是一个新颖的方法。使用一个卷积神经网络来直接预测多个边界框和每个边界框对应的类标签概率。YOLO 在整张图片上进行训练，并且直接对检测能力进行优化。这个模型与传统的目标检测方法相比有许多优势。
  - 首先，YOLO 的运行速度很快。由于我们将检测视为一个回归问题，我们不需要复杂的处理步骤。测试时只需要在一张新的图片上运行我们的神经网络，即可得到检测结果。我们的基础网络在不是用批处理时可以达到 45FPS 的处理速度（使用Titan X GPU），一个快速版本的运行速度可达到超过 150FPS 。这意味着我们的算法具有极佳的实时性。而且，YOLO 达到了其他实时目标检测系统平均精度的两倍。
  - 其次，YOLO 在作出预测时考虑到了整张图片。与滑动窗口和区域推荐方法不同，YOLO 在训练和测试时使用的是整张图片，因此可以隐式地考虑到场景提供的额外信息，进而产生更少的背景错误。
  - 还有，YOLO 学习到了目标的可泛化表示。由于 YOLO 具有高度的泛化能力，在应用于新领域或意想不到的输入时具有更高的鲁棒性。
- YOLO 在检测精度上目前仍落后于最新的目标检测系统。该方法尽管可以快速在图片中找到目标，在精确地定位目标（尤其是小目标）上仍然存在困难。

## 2 统一的检测方法

- 我们的检测系统将输入图像分割为 $S\times S$ 网格。如果一个目标的中心位于一个网格单元中，该网格单元负责对这个目标的检测。

- 每个网格单元预测 $B$ 个边界框和每个边界框对应的信心分数。这些信心分数反映了该模型对于对应的边界框中含有待测目标的自信程度以及边界框的预测精度。通常，信心分数定义为 $\rm Pr(Object) \times IOU_{pred}^{truth}$ 。如果网格单元中不存在待测目标，信心分数应为 $0$ 。有时，也将信心分数定义为 $\rm IOU_{pred}^{truth}$ 。

- 每个边界框包含 $5$ 个预测量：$x$ 、$y$ 、$w$ 、$h$ 和信心分数。坐标 $(x,y)$ 表示边界框中心相对与网格单元边界的偏移量。宽度 $w$ 和高度 $h$ 则是相对整张图片而言的。信心分数的预测值表示预测边界框与真实边界框之间的 $\rm IOU$ 。

- 每个网格单元同样预测 $C$ 个类条件概率 $\rm Pr({Class}_{i} | Object)$ 。对于每个网格单元，我们仅仅预测一个类标签概率集，尽管该网格单元中可能含有多个边界框。

- 测试时，我们将类条件概率与信心分数相乘。
  $$
  \rm Pr({Class}_i | Object) \times Pr(Object) \times IOU_{pred}^{truth} = Pr({Class}_i) \times IOU_{pred}^{truth} 
  $$
  从而给出每个边界框对应的每个类的信心分数。这种信心分数对该类物体出现在边界框中的概率和边界框与待测目标的贴合程度进行编码。

- **（图2：检测模型）：** 我们的系统将检测问题建模为回归问题。对于一张图片，预测表示为一个 $S \times S \times (B \times 5 + C)$ 维的张量。

- 对于YOLO方法在 PASCAL VOC 数据集上的评估，我们取 $S = 7$ ，$B = 2$ 。该数据集包含 $20$ 个类标签，即 $C = 20$ 。对于一张图片，我们的最终预测表示为一个 $7 \times 7 \times 30$ 维的张量。

### 2.1 网络设计

- 我们将该模型实现为一个卷积神经网络，在 PASCAL VOC 数据集上进行评估。网络最开始的卷积层从图像中提取特征，全连接层预测输出的概率和信心分数。
- 我们的网络结构源自于用于图像分类的 GoogLeNet 模型。我们的网络包含 $24$ 个卷积层，之后紧接着是 $2$ 个全连接层。与GoogLeNet 采用的 Inception Model 不同，我们简单地使用了 $1 \times 1$ 的 Reduction 层接 $3 \times 3$ 卷积层的结构。
- 我们也训练了一个 YOLO 的快速版本。快速 YOLO 使用了一个含有更少（$9$ 而不是 $24$）卷积层的神经网络，并且在这些层中使用了更少的滤波器。除了网络的尺寸，所有的训练和测试参数与完整版本相同。

### 2.2 训练

- 我们在ImageNet数据集上对卷积层进行了预训练。为了实现预训练，我们将模型中的前 $20$ 个卷积层加上一个平均池化层和一个全连接层组成一个预训练网络。我们对预训练网络进行了为期一周的训练，达到了ImageNet 2012 验证集中前 $5$ 名水平的 $88\%$ 的准确率，精度与Caffe's Model Zoo 中的 GoogLeNet 模型相当。我们使用 Darknet 框架来进行所有的训练和验证。

- 之后，我们使用预训练模型进行检测。【29】中指出向预训练模型中添加卷积层和全连接层可以提高模型的表现。按照【29】中的示例，我们向预训练模型中添加了带有随机初始化权重的 $4$ 个卷积层和 $2$ 个全连接层。由于检测往往需要更丰富的图像信息，我们将网络的输入分辨率从 $224 \times 224$ 提高到了 $448 \times 448$ 。

- 我们的输出层预测类标签概率和边界框坐标。我们使用图片的宽度和高度对边界框的宽度和高度进行归一化，使得其取值范围为 $0-1$ 。

- 我们对输出层使用线性激活函数，对其他所有层使用如下的激活函数：
  $$
  \begin{equation}
  \phi(x) =\left \{ 
  \begin{aligned}
  & x, && {\rm if} \space x > 0 \\
  &0.1x, && {\rm otherwise} 
  \end{aligned}
  \right.
  \end{equation}
  $$

- 我们对模型输出的平方和误差进行优化。我们使用平方和误差来便于优化，然而这与我们最大化平均精度的目标并不完全吻合。这种方法将定位误差和分类误差均等地加权，这可能并不理想。而且，在每张图片中，许多网格单元中并不含有任何待测目标。这会使得那些网格单元的信心分数趋向于 $0$ ，常常会过度增加含有待测目标的网格单元的梯度。这可能会增加模型的不稳定性，导致训练过程过早发散。

- 为了补救这一问题，我们增加边界框坐标预测带来损失，减少不含有待测目标的边界框的信心分数预测带来的损失。我们使用两个参数，$\lambda_{coord}$ 和 $\lambda_{noobj}$ ，对这两种损失进行加权。我们取 $\lambda_{coord} = 5$ 和 $\lambda_noobj = 0.5$ 。

- 平方和误差也对大边界框和小边界框的误差进行均等地加权。我们的误差应该反映出小误差在小边界框中比在大边界框中更严重。为了解决这一问题，我们预测边界框宽度和高度的平方根，而不是直接预测宽度和高度。

- YOLO 在每个网格单元上预测多个边界框。在训练时，我们只希望一个边界框预测器负责一个待测目标。我们根据预测结果的 ${\rm IOU}$ 最大原则为每个待测目标分配一个预测器。这使得边界框预测器之间具有了专一性。每个预测器都能更好地预测某些大小，宽高比，或者目标类别，提高了整体表现。

- 在训练期间，我们对如下的，多个部分组成的损失函数进行优化：

  - 边界框中心坐标误差对应的损失函数
    $$
    \lambda_{\rm coord} \sum_{i=0}^{S^2} \sum_{j=0}^{B}
    \mathbf1_{\rm ij}^{\rm obj} \left[
    	(x_i - \hat x_i)^2 + (y_i - \hat y_i)^2
    \right]
    $$

  - 边界框宽度高度误差对应的损失函数
    $$
    \lambda_{\rm coord} \sum_{i=0}^{S^2} \sum_{j=0}^{B} 
    \mathbf{1}_{\rm ij}^{\rm obj} \left[
        \bigg(\sqrt{w_i} - \sqrt{\hat w_i}\bigg)^2 +\bigg (\sqrt{h_i} - \sqrt{\hat h_i}\bigg)^2
    \right]
    $$

  - 边界框信心分数误差对应的损失函数
    $$
    \sum_{i=0}^{S^2} \sum_{j=0}^B \mathbf{1}_{\rm ij}^{\rm obj} \big( C_i - \hat C_i \big)^2
    + \lambda_{\rm noobj}
    \sum_{i=0}^{S^2} \sum_{j=0}^B \mathbf{1}_{\rm ij}^{\rm noobj} \big( C_i - \hat C_i \big)^2
    $$

  - 边界框类标签概率误差对应的损失函数
    $$
    \sum_{i=0}^{S^2} \sum_{c \in {\rm classes}} \mathbf{1}_{\rm i}^{\rm obj} \big(p_i(c) - \hat p_i (c) \big)^2
    $$


  其中，$\mathbf{1}_{\rm i}^{\rm obj}$ 表示网格单元 $i$ 中是否含有待测目标，$\mathbf{1}_{\rm ij}^{\rm obj}$ 表示第 $i$ 个网格单元中的第 $j$ 个边界框预测器负责该预测值。

- 注意该损失函数仅在网格单元中含有待测目标时对分类误差进行惩罚。同样，该损失函数仅在预测器对真实边界框负责时对边界框坐标误差进行惩罚。

- 我们在来自 PASCAL VOC 2007 和 2012 的训练集和验证集上对网络进行了大概 $135 \space {\rm  epoch}$ 的训练。在 2012 数据集上进行测试时，我们也将 2007 数据集中的测试数据用于训练。在训练过程中，我们取 ${\rm batch\_size} = 64$ ，$ {\rm momentum} = 0.9$ ，${\rm decay} = 0.0005$ 。

- 我们的学习速率改变策略如下：

  - 在开始的轮次中，我们从 $10^{-3}～10^{-2}$ 开始缓慢增加学习速率。
  - 如果开始时使用较大的学习速率，我们的模型可能会由于不稳定的梯度而发散。
  - 我们保持 $10^{-2}$ 的学习速率训练 $75$ 轮，之后使用 $10^{-3}$ 的学习速率训练 $30$ 轮，最后使用 $10^{-4}$ 的学习速率训练 $30$ 轮。

- 为了避免过拟合，我们使用 Dropout 和 Extensive Data Augmentation 策略。在第一个全连接层之后增加一个  ${\rm rate = 0.5}$ 的 Dropout 层，来避免层之间的 co-adaptation 。对于 Data Augmentation， 我们引入了高达原始图像大小 $20 \%$ 的随机缩放和变换。我们还在 HSV 颜色空间中进行随机的亮度和饱和度调整，调整的比例高达 $1.5$ 倍。

### 2.3 测试

- 与训练过程类似，在测试集图片上进行预测仅需要一个网络评估。在 PASCAL VOC 数据集上，该网络为每张图片预测 $98$ 个边界框，并且为每个边界框预测对应的类标签概率。 YOLO 由于没有采用基于分类器的方法，仅需要单一网络进行评估，在测试时运行速度极快。
- 网格设计在边界框预测上强化了空间上的多样性。通常，待测目标落在哪个网格单元中是显而易见的，而且网络为每个待测目标仅预测一个边界框。然而，一些大目标或者靠近多个网格单元边界的目标可以被多个网格单元很好地定位。非最大抑制可以被用来修正这些重复检测。与 R-CNN 和 DPM 相比对于检测性能的影响并不至关重要，非最大抑制增加了 $2 -3\% {\rm mAP}$ 。

### 2.4 YOLO 的局限性

- 由于每个网格单元仅预测 $2$ 个边界框并且这两个边界框使用同一个类标签概率，YOLO 对边界框预测施加了强烈的空间约束。这些空间约束限制了该模型能够区分的邻近物体的数量。该模型很难检测聚集在一起的大量小目标，例如成群的鸟。
- 由于该模型从数据中学习如何预测边界框，在泛化到新的目标或者不常见的长宽比、结构时会遇到困难。另一方面，该模型使用了相对粗糙的特征来预测边界框，由于网络结构中包含多个降采样层。
- 最后，尽管该方法在训练时使用了一个模拟检测性能的损失函数，这个损失函数对于较小的边界框中的误差和较大边界框中的误差同等对待。较大的边界框中的小误差通常是良性的，但是较小的边界框中的小误差对于 IOU 有更显著的影响。该方法的主要误差来源是不正确的定位。